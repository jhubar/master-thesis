{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhubar/master-thesis/blob/main/XlM_btt_large_qv_star.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7E3hFdIQBYu"
      },
      "source": [
        "\n",
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL18fbJlmXn8"
      },
      "outputs": [],
      "source": [
        "!rm -r transformers\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!cd tranformers\n",
        "!pip install -q ./transformers "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets seqeval"
      ],
      "metadata": {
        "id": "5X6FRLUGOES9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install detectron2 that matches pytorch 1.8\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "metadata": {
        "id": "iTY7cOwuNg3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "DHZkW3Ss7C6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "UbKp24nGOJqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_btt_large_qv = '/content/drive/MyDrive/LayoutLMv2/final/btt_large_star_qv'"
      ],
      "metadata": {
        "id": "ipGwX-Co9b7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = pd.read_pickle(path_btt_large_qv+'/pickel/train.pkl')\n",
        "\n",
        "val = pd.read_pickle(path_btt_large_qv+'/pickel/dev.pkl')\n",
        "test = pd.read_pickle(path_btt_large_qv+'/pickel/test.pkl')\n"
      ],
      "metadata": {
        "id": "znnyG9l4OL7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOxLV0JnQJWJ"
      },
      "source": [
        "## Prepare the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RJLFClPIYjt"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_labels = [item for sublist in train[1] for item in sublist] + [item for sublist in val[1] for item in sublist] + [item for sublist in test[1] for item in sublist]\n",
        "Counter(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter({'BASE_ID': 15134,\n",
        "         'Base': 9457,\n",
        "         'TAX_ID': 16694,\n",
        "         'TOT_AMOUNT_ID': 17413,\n",
        "         'TotAmount': 9199,\n",
        "         'noise': 1617014,\n",
        "         'tax': 9046})"
      ],
      "metadata": {
        "id": "_qMJ62xFKF_w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5jvOQR2Ivs5"
      },
      "source": [
        "As we can see, there are some labels that contain very few examples. Let's replace them by the \"neutral\" label \"O\" (which stands for \"Outside\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UzRGzqlIx22"
      },
      "outputs": [],
      "source": [
        "replacing_labels = {'noise': 'O'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldWhTh1wIyX-"
      },
      "outputs": [],
      "source": [
        "def replace_elem(elem):\n",
        "  try:\n",
        "    return replacing_labels[elem]\n",
        "  except KeyError:\n",
        "    return elem\n",
        "def replace_list(ls):\n",
        "  return [replace_elem(elem) for elem in ls]\n",
        "\n",
        "\n",
        "train[1] = [replace_list(ls) for ls in train[1]]\n",
        "val[1] = [replace_list(ls) for ls in val[1]]\n",
        "test[1] = [replace_list(ls) for ls in test[1]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIN8ptH4JD3T"
      },
      "outputs": [],
      "source": [
        "all_labels = [item for sublist in train[1] for item in sublist] + [item for sublist in val[1] for item in sublist] + [item for sublist in test[1] for item in sublist]\n",
        "Counter(all_labels)\n",
        "labels = list(set(all_labels))\n",
        "print(labels)\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for idx, label in enumerate(labels)}\n",
        "print(label2id)\n",
        "print(id2label)\n",
        "labels=['DueDate', 'TAX_ID', 'TOT_AMOUNT_ID', 'tax', 'TotAmount', 'Base', 'BASE_ID', 'O']\n",
        "label2id={'DueDate': 0, 'TAX_ID': 1, 'TOT_AMOUNT_ID': 2, 'tax': 3, 'TotAmount': 4, 'Base': 5, 'BASE_ID': 6, 'O': 7}\n",
        "id2label={0: 'DueDate', 1: 'TAX_ID', 2: 'TOT_AMOUNT_ID', 3: 'tax', 4: 'TotAmount', 5: 'Base', 6: 'BASE_ID', 7: 'O'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shn-dMRbJGuu"
      },
      "source": [
        "Now we have to save all the unique labels in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq5CmIRZUy9O"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from PIL import Image\n",
        "class BILLYDataset(Dataset):\n",
        "    \"\"\"Billy dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, annotations, image_dir, processor=None, max_length=512):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            annotations (List[List]): List of lists containing the word-level annotations (words, labels, boxes).\n",
        "            image_dir (string): Directory with all the document images.\n",
        "            processor (LayoutLMv2Processor): Processor to prepare the text + image.\n",
        "        \"\"\"\n",
        "        self.words, self.labels, self.boxes = annotations\n",
        "        self.image_dir = image_dir\n",
        "        self.image_file_names = [f for f in listdir(image_dir)]\n",
        "        self.processor = processor\n",
        "        self.max_length = max_length\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # first, take an image\n",
        "        item = self.image_file_names[idx]\n",
        "        image = Image.open(self.image_dir + item).convert(\"RGB\")\n",
        "\n",
        "        # get word-level annotations \n",
        "        words = self.words[idx]\n",
        "        \n",
        "        boxes = self.boxes[idx]\n",
        "        word_labels = self.labels[idx]\n",
        "\n",
        "        \n",
        "        assert len(words) == len(boxes) == len(word_labels)\n",
        "       \n",
        "        word_labels = [label2id[label] for label in word_labels]\n",
        "       \n",
        "        # use processor to prepare everything\n",
        "        encoded_inputs = processor(image, words, boxes=boxes, word_labels=word_labels,\n",
        "                              padding=\"max_length\", truncation=True, max_length=512, return_token_type_ids=True,return_tensors=\"pt\")\n",
        "        \n",
        "        # remove batch dimension\n",
        "        for k,v in encoded_inputs.items():\n",
        "          encoded_inputs[k] = v.squeeze()\n",
        "\n",
        "        assert encoded_inputs.input_ids.shape == torch.Size([512])\n",
        "        assert encoded_inputs.attention_mask.shape == torch.Size([512])\n",
        "        assert encoded_inputs.token_type_ids.shape == torch.Size([512])\n",
        "        assert encoded_inputs.bbox.shape == torch.Size([512, 4])\n",
        "        assert encoded_inputs.image.shape == torch.Size([3, 224, 224])\n",
        "        assert encoded_inputs.labels.shape == torch.Size([512]) \n",
        "      \n",
        "        return encoded_inputs\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izA9k5e-egyy"
      },
      "outputs": [],
      "source": [
        "from transformers import LayoutLMv2FeatureExtractor\n",
        "from transformers import LayoutXLMTokenizer\n",
        "from transformers import LayoutXLMProcessor\n",
        "\n",
        "\n",
        "# feature_extractor = LayoutLMv2FeatureExtractor(apply_ocr=False)\n",
        "# tokenizer = LayoutXLMTokenizer.from_pretrained(\"microsoft/layoutxlm-base\")\n",
        "# processor = LayoutXLMProcessor(feature_extractor,tokenizer)\n",
        "processor = LayoutXLMProcessor.from_pretrained(\"microsoft/layoutxlm-base\", apply_ocr=False)\n",
        "\n",
        "train_dataset = BILLYDataset(annotations=train,\n",
        "                            image_dir= path_btt_large_qv+'/train/image/', \n",
        "                            processor=processor)\n",
        "print(len(train_dataset))\n",
        "val_dataset = BILLYDataset(annotations=val,\n",
        "                            image_dir=path_btt_large_qv+'/dev/image/', \n",
        "                            processor=processor)\n",
        "print(len(val_dataset))\n",
        "test_dataset = BILLYDataset(annotations=test,\n",
        "                            image_dir=path_btt_large_qv+'/test/image/', \n",
        "                            processor=processor)\n",
        "print(len(test_dataset))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQJLuPPf27V"
      },
      "source": [
        "Next, we create corresponding dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI-eM0m4fmfF"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 2\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "print(len(train_dataloader))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)\n",
        "print(len(val_dataloader))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2)\n",
        "print(len(test_dataloader))\n",
        "print(len(test_dataloader)+len(test_dataloader)+len(train_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHgKGixHgIIC"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "train the model\n",
        "learning rate = 5e-5 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score)\n",
        "\n",
        "def results_test(preds, out_label_ids, labels):\n",
        "  preds = np.argmax(preds, axis=2)\n",
        "\n",
        "  label_map = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "  out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "  preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "\n",
        "  for i in range(out_label_ids.shape[0]):\n",
        "      for j in range(out_label_ids.shape[1]):\n",
        "          if out_label_ids[i, j] != -100:\n",
        "              out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
        "              preds_list[i].append(label_map[preds[i][j]])\n",
        "\n",
        "  \n",
        "  results = {\n",
        "      \"precision\": precision_score(out_label_list, preds_list),\n",
        "      \"recall\": recall_score(out_label_list, preds_list),\n",
        "      \"f1\": f1_score(out_label_list, preds_list),\n",
        "  }\n",
        " \n",
        "  return results,out_label_list, preds_list"
      ],
      "metadata": {
        "id": "AjcHF59ZKOWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LayoutLMv2ForTokenClassification, AdamW\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "import numpy as np\n",
        "print(torch.cuda.get_device_name(0))\n",
        "model = LayoutLMv2ForTokenClassification.from_pretrained(\"microsoft/layoutxlm-base\",\n",
        "                                                                      num_labels=len(labels))\n",
        "labels = list(set(all_labels))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cuda'\n",
        "print(device)\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
      ],
      "metadata": {
        "id": "YPLqj_CMv2tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxahVHZ0NKq7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "val_iterator = iter(val_dataloader)\n",
        "global_step = 0\n",
        "num_train_epochs = 2\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_precision = []\n",
        "val_recall = []\n",
        "val_f1 = []\n",
        "preds_val = None\n",
        "out_label_ids = None\n",
        "batch_logits_array = []\n",
        "out_label_list=[]\n",
        "preds_list=[]\n",
        "#put the model in training mode\n",
        "val_batch_idx = 0\n",
        "for epoch in range(num_train_epochs):  \n",
        "   print(\"Epoch:\", epoch)\n",
        "   loop = tqdm(train_dataloader, leave=True)\n",
        "   for batch_id, batch in enumerate(loop):\n",
        "        model.train() \n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        bbox = batch['bbox'].to(device)\n",
        "        image = batch['image'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(input_ids=input_ids,\n",
        "                        bbox=bbox,\n",
        "                        image=image,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids,\n",
        "                        labels=labels) \n",
        "        loss = outputs.loss\n",
        "        train_loss.append(loss.item())\n",
        "        # writer.add_scalar(\"Loss/train\", loss.item(), input_ids)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Testing part\n",
        "        if val_batch_idx >= len(val_iterator):\n",
        "            val_iterator = iter(val_dataloader)\n",
        "            val_batch_idx = 0\n",
        "        val_batch_idx += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            batch = next(val_iterator)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            bbox = batch['bbox'].to(device)\n",
        "            image = batch['image'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            token_type_ids = batch['token_type_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            # forward pass\n",
        "            outputs = model(input_ids=input_ids, bbox=bbox, image=image, attention_mask=attention_mask, \n",
        "                            token_type_ids=token_type_ids, labels=labels)\n",
        "            if preds_val is None:\n",
        "                preds_val = outputs.logits.detach().cpu().numpy()\n",
        "                out_label_ids = batch[\"labels\"].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds_val = np.append(preds_val, outputs.logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, batch[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "       \n",
        "\n",
        "        \n",
        "        loss = outputs.loss\n",
        "        val_loss.append(loss.item())\n",
        "         \n",
        "        if global_step % 100 == 0 or global_step == 0:\n",
        "            val_result,out_label_l,preds_l = results_test(preds_val, out_label_ids, list(set(all_labels)))\n",
        "            val_precision.append(val_result['precision'])\n",
        "            val_recall.append(val_result['recall'])\n",
        "            val_f1.append(val_result['f1'])\n",
        "            out_label_list.append(out_label_l)\n",
        "            preds_list.append(preds_l)\n",
        "\n",
        "        \n",
        "            \n",
        "            print(\"Overall results:\", val_result)\n",
        "            print(f\"Loss after {global_step} steps: {train_loss[-1]}\")\n",
        "            print(\"Validation loss: {}\".format(loss.item()))\n",
        "        global_step += 1\n",
        "\n",
        "  #  print(f\"{epoch} |  | {loss:^12.6f} | {val_loss:^10.6f}  \")\n",
        "\n",
        "\n",
        "model.save_pretrained(path_btt_large_qv +\"check_points/LargeCheckpoints_xlm_lr_1e5\")\n",
        "path_model = path_btt_large_qv +'/model/large_model_xlm_btt_qv_lr_star_1e5.pt'\n",
        "torch.save(model, path_model)\n",
        "\n",
        "# define data\n",
        "data_loss = pd.DataFrame({'batch_loss_array': train_loss,'val_loss':val_loss})\n",
        "data_loss.to_csv(path_btt_large_qv + '/output/logits_btt_qv_large_star_lr_1e5.csv')\n",
        "data_loss = pd.DataFrame({'precison':val_precision,'recall':val_recall,'f1':val_f1})\n",
        "data_loss.to_csv(path_btt_large_qv + '/output/metrics.csv')\n",
        "data_loss = pd.DataFrame({'preds_list':preds_list,'out_label_list':out_label_list})\n",
        "data_loss.to_csv(path_btt_large_qv + '/output/classification_reports.csv')\n",
        "# data_logits = asarray([batch_logits_array])\n",
        "# save to csv file\n",
        "# writer.flush()\n",
        "\n",
        "\n",
        "# savetxt(path_btt_large_qv + '/logits_btt_qv_large.csv', data_logits, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "\n",
        "# data_loss = pd.read_csv(path_btt_large_qv + '/output/logits_btt_qv_large_star_lr_1e5.csv')\n",
        "\n",
        "\n",
        "x_avg_train_loss = []\n",
        "y_avg_train_loss = []\n",
        "x_avg_val_loss = []\n",
        "y_avg_val_loss = []\n",
        "\n",
        "x_val_precision = []\n",
        "y_val_precision = []\n",
        "\n",
        "x_avg_val_recall = []\n",
        "y_avg_val_recall = []\n",
        "\n",
        "x_avg_val_f1 = []\n",
        "y_avg_val_f1 = []\n",
        "\n",
        "for i in range(0,len(train_loss)):\n",
        "   if i%100==0:\n",
        "      x_avg_train_loss.append(i)\n",
        "      y_avg_train_loss.append(train_loss[i]) \n",
        "\n",
        "for i in range(0,len(val_loss)):\n",
        "   if i%100==0:\n",
        "      x_avg_val_loss.append(i)\n",
        "      y_avg_val_loss.append(val_loss[i]) \n",
        "      \n",
        "\n",
        "for i in range(0,len(val_loss)):\n",
        "  if i%100==0:\n",
        "    try:\n",
        "      x_val_precision.append(i)\n",
        "      y_val_precision.append(val_precision[i])\n",
        "      x_avg_val_recall.append(i)\n",
        "      y_avg_val_recall.append(val_recall[i])\n",
        "      x_avg_val_f1.append(i)\n",
        "      y_avg_val_f1.append(val_f1[i])\n",
        "    except:\n",
        "      break\n",
        "        \n",
        "\n",
        "# # Loss \n",
        "plt.plot((train_loss), label = 'trainnning loss',color= 'navajowhite')\n",
        "plt.plot((val_loss),label = 'validation loss',color='dodgerblue')\n",
        "plt.plot(x_avg_train_loss,y_avg_train_loss,label='trainning loss every 100 steps',linewidth=2,color='orange')\n",
        "plt.plot(x_avg_val_loss,y_avg_val_loss,label='trainning loss every 100 steps',linewidth=2,color='blue')\n",
        "\n",
        "\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig(path_btt_large_qv+'/btt_qv_lr__star_1e5_log_test.png')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Loss \n",
        "plt.plot((train_loss), label = 'trainnning loss',color= 'navajowhite')\n",
        "plt.plot((val_loss),label = 'validation loss',color='dodgerblue')\n",
        "plt.plot(x_avg_train_loss,y_avg_train_loss,label='trainning loss every 100 steps',linewidth=2,color='orange')\n",
        "plt.plot(x_avg_val_loss,y_avg_val_loss,label='trainning loss every 100 steps',linewidth=2,color='blue')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig(path_btt_large_qv+'/btt_qv_star_lr_1e5_test.png')\n",
        "plt.show()\n",
        "# precision - recall - f1\n",
        "# plt.plot((data_loss['precison']), label = 'val precision',color= 'navajowhite')\n",
        "# plt.plot((data_loss['recall']),label = 'val recall',color='dodgerblue')\n",
        "# plt.plot((data_loss['f1']),label = 'f1',color='blue')\n",
        "# plt.plot((data_loss['train_loss']), label = 'trainnning loss',color= 'navajowhite')\n",
        "# plt.plot(x_avg_train_loss,y_avg_train_loss,label='trainning loss every 100 steps',linewidth=2,color='orange')\n",
        "# plt.plot(x_avg_val_loss,y_avg_val_loss,label='trainning loss every 100 steps',linewidth=2,color='blue')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('')\n",
        "# plt.legend()\n",
        "# plt.savefig(path_btt_large_qv+'/btt_qv_star_lr_1e5_test.png')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "MSng0Gb8fZy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "path_model =  path_btt_large_qv +'/model/large_model_xlm_btt_qv_lr_star_1e5.pt'\n",
        "model = torch.load(path_model, map_location=torch.device(device))"
      ],
      "metadata": {
        "id": "yk1-Cv1NHbLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "0Z2aGMzywtFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDREDNOhPv0C"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Let's evaluate the model on the test set. First, let's do a sanity check on the first example of the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score)\n",
        "\n",
        "def results_test(preds, out_label_ids, labels):\n",
        "  preds = np.argmax(preds, axis=2)\n",
        "\n",
        "  label_map = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "  out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "  preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "\n",
        "  for i in range(out_label_ids.shape[0]):\n",
        "      for j in range(out_label_ids.shape[1]):\n",
        "          if out_label_ids[i, j] != -100:\n",
        "              out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
        "              preds_list[i].append(label_map[preds[i][j]])\n",
        "\n",
        "  \n",
        "  results = {\n",
        "      \"precision\": precision_score(out_label_list, preds_list),\n",
        "      \"recall\": recall_score(out_label_list, preds_list),\n",
        "      \"f1\": f1_score(out_label_list, preds_list),\n",
        "  }\n",
        "  return results, classification_report(out_label_list, preds_list)"
      ],
      "metadata": {
        "id": "_UDuR5nhrThX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QGUtQuIacyF"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score)\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "preds_val = None\n",
        "out_label_ids = None\n",
        "\n",
        "# put model in evaluation mode\n",
        "model.eval()\n",
        "batch_test_array = []\n",
        "for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "    with torch.no_grad():\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        bbox = batch['bbox'].to(device)\n",
        "        image = batch['image'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(input_ids=input_ids, bbox=bbox, image=image, attention_mask=attention_mask, \n",
        "                        token_type_ids=token_type_ids, labels=labels)\n",
        "      \n",
        "        \n",
        "        if preds_val is None:\n",
        "          preds_val = outputs.logits.detach().cpu().numpy()\n",
        "          out_label_ids = batch[\"labels\"].detach().cpu().numpy()\n",
        "        else:\n",
        "          preds_val = np.append(preds_val, outputs.logits.detach().cpu().numpy(), axis=0)\n",
        "          out_label_ids = np.append(\n",
        "              out_label_ids, batch[\"labels\"].detach().cpu().numpy(), axis=0\n",
        "          )\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPW1CISc0DL9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score)\n",
        "\n",
        "def results_test(preds, out_label_ids, labels):\n",
        "  preds = np.argmax(preds, axis=2)\n",
        "\n",
        "  label_map = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "  out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "  preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "\n",
        "  for i in range(out_label_ids.shape[0]):\n",
        "      for j in range(out_label_ids.shape[1]):\n",
        "          if out_label_ids[i, j] != -100:\n",
        "              out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
        "              preds_list[i].append(label_map[preds[i][j]])\n",
        "\n",
        "  \n",
        "  results = {\n",
        "      \"precision\": precision_score(out_label_list, preds_list),\n",
        "      \"recall\": recall_score(out_label_list, preds_list),\n",
        "      \"f1\": f1_score(out_label_list, preds_list),\n",
        "  }\n",
        "  return results, classification_report(out_label_list, preds_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVuQ73870FMF"
      },
      "outputs": [],
      "source": [
        "labels = list(set(all_labels))\n",
        "val_result, class_report = results_test(preds_val, out_label_ids, labels)\n",
        "print(\"Overall results:\", val_result)\n",
        "print(class_report)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "XlM_btt_large_qv_star.ipynb",
      "provenance": [],
      "private_outputs": true,
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
